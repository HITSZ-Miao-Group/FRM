{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runing LLaMA-2-13B W2A16 quantized model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the prebuilt quantized model:\n",
    "We have provide the prebuilt quantized model on Huggingface. In order to download the large weights, we'll have to use git lfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git lfs install\n",
    "\n",
    "# download LLaMA-2-13b-w2a16 quantization\n",
    "!git clone https://huggingface.co/FRM-PTQ/llama-2-13b-w2a16-frm-ptq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/frm-ptq/lib/python3.11/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from accelerate import infer_auto_device_map, dispatch_model\n",
    "import torch\n",
    "from datautils import get_loaders, test_ppl\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, tokenizer):\n",
    "    '''\n",
    "    Note: evaluation simply move model to single GPU. \n",
    "    Therefor, to evaluate large model such as Llama-2-70B on single A100-80GB,\n",
    "    please activate '--real_quant'.\n",
    "    '''\n",
    "    # import pdb;pdb.set_trace()\n",
    "    block_class_name = model.model.layers[0].__class__.__name__\n",
    "    device_map = infer_auto_device_map(model, max_memory={i: '40GB' for i in range(torch.cuda.device_count())}, no_split_module_classes=[block_class_name])\n",
    "    model = dispatch_model(model, device_map=device_map)\n",
    "    results = {}\n",
    "\n",
    "    datasets = [\"c4\",\"wikitext2\"]\n",
    "    ppl_results = test_ppl(model, tokenizer, datasets, 2048)\n",
    "    for dataset in ppl_results:\n",
    "        print(f'{dataset} perplexity: {ppl_results[dataset]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading quantized model from ./llama-2-13b-w2a16-frm-ptq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 93.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-computed quantized weights...\n",
      "Loading pre-computed quantized weights Successfully\n",
      "get_c4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 356317 examples [00:01, 179607.44 examples/s]\n",
      "Generating validation split: 45576 examples [00:00, 125660.30 examples/s]\n",
      "100%|██████████| 256/256 [02:00<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c4:9.418624877929688\n",
      "get_wikitext2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 10.5k/10.5k [00:00<00:00, 8.99MB/s]\n",
      "Downloading data: 100%|██████████| 733k/733k [00:00<00:00, 817kB/s]\n",
      "Downloading data: 100%|██████████| 6.36M/6.36M [00:01<00:00, 6.18MB/s]\n",
      "Downloading data: 100%|██████████| 657k/657k [00:00<00:00, 923kB/s]\n",
      "Generating test split: 100%|██████████| 4358/4358 [00:00<00:00, 146146.03 examples/s]\n",
      "Generating train split: 100%|██████████| 36718/36718 [00:00<00:00, 204676.88 examples/s]\n",
      "Generating validation split: 100%|██████████| 3760/3760 [00:00<00:00, 194482.46 examples/s]\n",
      "100%|██████████| 166/166 [01:15<00:00,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikitext2:7.127840995788574\n",
      "c4 perplexity: 9.42\n",
      "wikitext2 perplexity: 7.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from quantize.int_linear_real import load_quantized_model\n",
    "from accelerate import infer_auto_device_map, dispatch_model\n",
    "import torch\n",
    "\n",
    "model_path = './llama-2-13b-w2a16-frm-ptq'\n",
    "wbits = 2\n",
    "abits = 16\n",
    "group_size = 128\n",
    "use_act_quant = False\n",
    "sensitive_group = [0, 39, 3, 1, 28, 2, 38, 24]\n",
    "robust_group = [27, 31, 29, 30, 34, 35]\n",
    "model, tokenizer = load_quantized_model(model_path=model_path, wbits=wbits, abits=abits, group_size=group_size, use_act_quant=use_act_quant,sensitive_group=sensitive_group, robust_group=robust_group)\n",
    "model = model.cuda()\n",
    "# Test PPL\n",
    "evaluate(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 5.67k/5.67k [00:00<00:00, 4.99MB/s]\n",
      "2024-12-15:17:53:00,122 WARNING  [huggingface.py:118] `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "2024-12-15:17:53:00,834 WARNING  [huggingface.py:337] Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n",
      "2024-12-15:17:53:04,118 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "/root/anaconda3/envs/frm-ptq/lib/python3.11/site-packages/datasets/load.py:1461: FutureWarning: The repository for piqa contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/piqa\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Downloading builder script: 100%|██████████| 5.36k/5.36k [00:00<00:00, 9.27MB/s]\n",
      "Downloading readme: 100%|██████████| 8.41k/8.41k [00:00<00:00, 8.18MB/s]\n",
      "Downloading data: 100%|██████████| 1.82M/1.82M [00:00<00:00, 9.19MB/s]\n",
      "Downloading data: 100%|██████████| 815k/815k [00:00<00:00, 4.45MB/s]\n",
      "Generating train split: 100%|██████████| 16113/16113 [00:00<00:00, 48941.64 examples/s]\n",
      "Generating test split: 100%|██████████| 3084/3084 [00:00<00:00, 52533.35 examples/s]\n",
      "Generating validation split: 100%|██████████| 1838/1838 [00:00<00:00, 50027.13 examples/s]\n",
      "Downloading readme: 100%|██████████| 9.00k/9.00k [00:00<00:00, 7.54MB/s]\n",
      "Downloading data: 100%|██████████| 331k/331k [00:00<00:00, 522kB/s]\n",
      "Downloading data: 100%|██████████| 346k/346k [00:00<00:00, 376kB/s]\n",
      "Downloading data: 100%|██████████| 86.1k/86.1k [00:00<00:00, 94.6kB/s]\n",
      "Generating train split: 100%|██████████| 2251/2251 [00:00<00:00, 150589.80 examples/s]\n",
      "Generating test split: 100%|██████████| 2376/2376 [00:00<00:00, 170120.63 examples/s]\n",
      "Generating validation split: 100%|██████████| 570/570 [00:00<00:00, 100232.82 examples/s]\n",
      "Downloading data: 100%|██████████| 190k/190k [00:00<00:00, 287kB/s]\n",
      "Downloading data: 100%|██████████| 204k/204k [00:00<00:00, 308kB/s]\n",
      "Downloading data: 100%|██████████| 55.7k/55.7k [00:00<00:00, 84.7kB/s]\n",
      "Generating train split: 100%|██████████| 1119/1119 [00:00<00:00, 98000.21 examples/s]\n",
      "Generating test split: 100%|██████████| 1172/1172 [00:00<00:00, 112722.70 examples/s]\n",
      "Generating validation split: 100%|██████████| 299/299 [00:00<00:00, 44158.34 examples/s]\n",
      "/root/anaconda3/envs/frm-ptq/lib/python3.11/site-packages/datasets/load.py:1461: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Downloading builder script: 100%|██████████| 4.36k/4.36k [00:00<00:00, 8.27MB/s]\n",
      "Downloading metadata: 100%|██████████| 2.53k/2.53k [00:00<00:00, 6.37MB/s]\n",
      "Downloading readme: 100%|██████████| 6.84k/6.84k [00:00<00:00, 11.8MB/s]\n",
      "Downloading data: 47.5MB [00:00, 80.2MB/s]                            \n",
      "Downloading data: 11.8MB [00:00, 38.6MB/s]                           \n",
      "Downloading data: 12.2MB [00:00, 41.0MB/s]                           \n",
      "Generating train split: 100%|██████████| 39905/39905 [00:01<00:00, 20970.54 examples/s]\n",
      "Generating test split: 100%|██████████| 10003/10003 [00:00<00:00, 21180.84 examples/s]\n",
      "Generating validation split: 100%|██████████| 10042/10042 [00:00<00:00, 20919.78 examples/s]\n",
      "Map: 100%|██████████| 39905/39905 [00:04<00:00, 8834.05 examples/s] \n",
      "Map: 100%|██████████| 10042/10042 [00:01<00:00, 8597.40 examples/s]\n",
      "2024-12-15:17:54:09,020 WARNING  [task.py:763] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-12-15:17:54:09,020 WARNING  [task.py:775] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "/root/anaconda3/envs/frm-ptq/lib/python3.11/site-packages/datasets/load.py:1461: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Downloading builder script: 100%|██████████| 30.7k/30.7k [00:00<00:00, 18.4MB/s]\n",
      "Downloading readme: 100%|██████████| 18.2k/18.2k [00:00<00:00, 14.0MB/s]\n",
      "Downloading data: 100%|██████████| 4.12M/4.12M [00:00<00:00, 12.6MB/s]\n",
      "Generating train split: 100%|██████████| 9427/9427 [00:00<00:00, 47560.10 examples/s]\n",
      "Generating validation split: 100%|██████████| 3270/3270 [00:00<00:00, 52738.25 examples/s]\n",
      "Generating test split: 100%|██████████| 3245/3245 [00:00<00:00, 55057.61 examples/s]\n",
      "/root/anaconda3/envs/frm-ptq/lib/python3.11/site-packages/datasets/load.py:1461: FutureWarning: The repository for winogrande contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/winogrande\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Downloading builder script: 100%|██████████| 5.65k/5.65k [00:00<00:00, 9.79MB/s]\n",
      "Downloading readme: 100%|██████████| 9.97k/9.97k [00:00<00:00, 9.73MB/s]\n",
      "Downloading data: 100%|██████████| 3.40M/3.40M [00:00<00:00, 12.9MB/s]\n",
      "Generating train split: 100%|██████████| 40398/40398 [00:00<00:00, 51570.46 examples/s]\n",
      "Generating test split: 100%|██████████| 1767/1767 [00:00<00:00, 52598.10 examples/s]\n",
      "Generating validation split: 100%|██████████| 1267/1267 [00:00<00:00, 50660.96 examples/s]\n",
      "/root/anaconda3/envs/frm-ptq/lib/python3.11/site-packages/datasets/load.py:1461: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Downloading builder script: 100%|██████████| 5.86k/5.86k [00:00<00:00, 21.9MB/s]\n",
      "Downloading readme: 100%|██████████| 1.11k/1.11k [00:00<00:00, 3.20MB/s]\n",
      "Downloading data: 100%|██████████| 166M/166M [00:07<00:00, 21.8MB/s] \n",
      "Generating test split: 378 examples [00:00, 3089.12 examples/s]\n",
      "Generating validation split: 41 examples [00:00, 8729.71 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 74.77 examples/s]\n",
      "Generating test split: 100 examples [00:00, 836.07 examples/s]\n",
      "Generating validation split: 8 examples [00:00, 1896.59 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 74.37 examples/s]\n",
      "Generating test split: 151 examples [00:00, 1226.63 examples/s]\n",
      "Generating validation split: 17 examples [00:00, 4806.74 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 75.27 examples/s]\n",
      "Generating test split: 102 examples [00:00, 801.20 examples/s]\n",
      "Generating validation split: 11 examples [00:00, 4014.39 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 75.32 examples/s]\n",
      "Generating test split: 270 examples [00:00, 2289.10 examples/s]\n",
      "Generating validation split: 29 examples [00:00, 8497.02 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 74.76 examples/s]\n",
      "Generating test split: 100 examples [00:00, 821.78 examples/s]\n",
      "Generating validation split: 11 examples [00:00, 2884.31 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 75.14 examples/s]\n",
      "Generating test split: 310 examples [00:00, 2482.83 examples/s]\n",
      "Generating validation split: 32 examples [00:00, 7742.14 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 68.74 examples/s]\n",
      "Generating test split: 145 examples [00:00, 1207.28 examples/s]\n",
      "Generating validation split: 16 examples [00:00, 4978.03 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 74.17 examples/s]\n",
      "Generating test split: 100 examples [00:00, 846.49 examples/s]\n",
      "Generating validation split: 11 examples [00:00, 3091.49 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 74.29 examples/s]\n",
      "Generating test split: 216 examples [00:00, 1716.72 examples/s]\n",
      "Generating validation split: 23 examples [00:00, 6429.55 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 75.74 examples/s]\n",
      "Generating test split: 235 examples [00:00, 1896.49 examples/s]\n",
      "Generating validation split: 26 examples [00:00, 8178.48 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 74.90 examples/s]\n",
      "Generating test split: 144 examples [00:00, 1192.13 examples/s]\n",
      "Generating validation split: 16 examples [00:00, 3626.53 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 73.89 examples/s]\n",
      "Generating test split: 203 examples [00:00, 1654.88 examples/s]\n",
      "Generating validation split: 22 examples [00:00, 5138.07 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 75.29 examples/s]\n",
      "Generating test split: 100 examples [00:00, 846.89 examples/s]\n",
      "Generating validation split: 11 examples [00:00, 3349.84 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 74.45 examples/s]\n",
      "Generating test split: 100 examples [00:00, 846.77 examples/s]\n",
      "Generating validation split: 9 examples [00:00, 3550.48 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 74.20 examples/s]\n",
      "Generating test split: 135 examples [00:00, 1118.24 examples/s]\n",
      "Generating validation split: 14 examples [00:00, 4826.19 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 73.61 examples/s]\n",
      "Generating test split: 152 examples [00:00, 1250.46 examples/s]\n",
      "Generating validation split: 16 examples [00:00, 6114.15 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 72.62 examples/s]\n",
      "Generating test split: 112 examples [00:00, 921.85 examples/s]\n",
      "Generating validation split: 11 examples [00:00, 3791.38 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 72.95 examples/s]\n",
      "Generating test split: 100 examples [00:00, 810.96 examples/s]\n",
      "Generating validation split: 11 examples [00:00, 3386.48 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 74.49 examples/s]\n",
      "Generating test split: 173 examples [00:00, 1435.26 examples/s]\n",
      "Generating validation split: 22 examples [00:00, 7003.77 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 76.00 examples/s]\n",
      "Generating test split: 265 examples [00:00, 2089.27 examples/s]\n",
      "Generating validation split: 29 examples [00:00, 7696.94 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 75.03 examples/s]\n",
      "Generating test split: 272 examples [00:00, 2127.27 examples/s]\n",
      "Generating validation split: 31 examples [00:00, 5275.00 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 68.28 examples/s]\n",
      "Generating test split: 783 examples [00:00, 5234.87 examples/s]\n",
      "Generating validation split: 86 examples [00:00, 19798.57 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 78.22 examples/s]\n",
      "Generating test split: 234 examples [00:00, 1890.81 examples/s]\n",
      "Generating validation split: 25 examples [00:00, 5792.60 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 75.18 examples/s]\n",
      "Generating test split: 100 examples [00:00, 851.69 examples/s]\n",
      "Generating validation split: 10 examples [00:00, 3832.16 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 73.44 examples/s]\n",
      "Generating test split: 306 examples [00:00, 2439.80 examples/s]\n",
      "Generating validation split: 33 examples [00:00, 8122.77 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 75.21 examples/s]\n",
      "Generating test split: 223 examples [00:00, 1817.11 examples/s]\n",
      "Generating validation split: 23 examples [00:00, 5849.44 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 75.68 examples/s]\n",
      "Generating test split: 282 examples [00:00, 2208.25 examples/s]\n",
      "Generating validation split: 31 examples [00:00, 5980.56 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 76.15 examples/s]\n",
      "Generating test split: 103 examples [00:00, 864.82 examples/s]\n",
      "Generating validation split: 11 examples [00:00, 1954.81 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 74.37 examples/s]\n",
      "Generating test split: 166 examples [00:00, 1374.26 examples/s]\n",
      "Generating validation split: 18 examples [00:00, 4361.49 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 68.62 examples/s]\n",
      "Generating test split: 100 examples [00:00, 810.57 examples/s]\n",
      "Generating validation split: 11 examples [00:00, 4286.66 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 63.23 examples/s]\n",
      "Generating test split: 100 examples [00:00, 783.74 examples/s]\n",
      "Generating validation split: 11 examples [00:00, 4624.83 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 78.79 examples/s]\n",
      "Generating test split: 198 examples [00:00, 1438.60 examples/s]\n",
      "Generating validation split: 22 examples [00:00, 6794.40 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 68.42 examples/s]\n",
      "Generating test split: 390 examples [00:00, 3034.37 examples/s]\n",
      "Generating validation split: 43 examples [00:00, 10080.77 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 73.21 examples/s]\n",
      "Generating test split: 110 examples [00:00, 929.93 examples/s]\n",
      "Generating validation split: 12 examples [00:00, 3155.98 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 75.02 examples/s]\n",
      "Generating test split: 131 examples [00:00, 1074.98 examples/s]\n",
      "Generating validation split: 12 examples [00:00, 3287.07 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 71.86 examples/s]\n",
      "Generating test split: 100 examples [00:00, 817.01 examples/s]\n",
      "Generating validation split: 11 examples [00:00, 3511.75 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 76.25 examples/s]\n",
      "Generating test split: 193 examples [00:00, 1594.17 examples/s]\n",
      "Generating validation split: 21 examples [00:00, 6646.57 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 75.43 examples/s]\n",
      "Generating test split: 245 examples [00:00, 1976.17 examples/s]\n",
      "Generating validation split: 27 examples [00:00, 5124.96 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 74.31 examples/s]\n",
      "Generating test split: 612 examples [00:00, 4535.55 examples/s]\n",
      "Generating validation split: 69 examples [00:00, 11492.16 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 75.48 examples/s]\n",
      "Generating test split: 114 examples [00:00, 952.03 examples/s]\n",
      "Generating validation split: 12 examples [00:00, 3697.87 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 74.22 examples/s]\n",
      "Generating test split: 201 examples [00:00, 1661.09 examples/s]\n",
      "Generating validation split: 22 examples [00:00, 4655.17 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 75.21 examples/s]\n",
      "Generating test split: 238 examples [00:00, 1885.45 examples/s]\n",
      "Generating validation split: 26 examples [00:00, 5907.79 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 74.15 examples/s]\n",
      "Generating test split: 545 examples [00:00, 4117.88 examples/s]\n",
      "Generating validation split: 60 examples [00:00, 10136.47 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 74.11 examples/s]\n",
      "Generating test split: 324 examples [00:00, 2488.45 examples/s]\n",
      "Generating validation split: 35 examples [00:00, 8095.77 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 74.04 examples/s]\n",
      "Generating test split: 171 examples [00:00, 1395.11 examples/s]\n",
      "Generating validation split: 19 examples [00:00, 5656.31 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 71.98 examples/s]\n",
      "Generating test split: 163 examples [00:00, 1360.63 examples/s]\n",
      "Generating validation split: 18 examples [00:00, 4441.29 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 75.01 examples/s]\n",
      "Generating test split: 165 examples [00:00, 1340.72 examples/s]\n",
      "Generating validation split: 18 examples [00:00, 3685.68 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 74.64 examples/s]\n",
      "Generating test split: 108 examples [00:00, 856.79 examples/s]\n",
      "Generating validation split: 11 examples [00:00, 1886.24 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 66.13 examples/s]\n",
      "Generating test split: 204 examples [00:00, 1623.56 examples/s]\n",
      "Generating validation split: 22 examples [00:00, 4302.85 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 73.36 examples/s]\n",
      "Generating test split: 121 examples [00:00, 1000.51 examples/s]\n",
      "Generating validation split: 13 examples [00:00, 3784.68 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 75.85 examples/s]\n",
      "Generating test split: 1534 examples [00:00, 8763.28 examples/s]\n",
      "Generating validation split: 170 examples [00:00, 17704.96 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 77.31 examples/s]\n",
      "Generating test split: 346 examples [00:00, 2704.84 examples/s]\n",
      "Generating validation split: 38 examples [00:00, 7309.50 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 74.44 examples/s]\n",
      "Generating test split: 311 examples [00:00, 2477.08 examples/s]\n",
      "Generating validation split: 34 examples [00:00, 10706.99 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 74.38 examples/s]\n",
      "Generating test split: 237 examples [00:00, 1851.05 examples/s]\n",
      "Generating validation split: 26 examples [00:00, 5098.03 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 75.62 examples/s]\n",
      "Generating test split: 126 examples [00:00, 1025.58 examples/s]\n",
      "Generating validation split: 14 examples [00:00, 4239.12 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 75.58 examples/s]\n",
      "Generating test split: 895 examples [00:00, 6179.52 examples/s]\n",
      "Generating validation split: 100 examples [00:00, 16798.05 examples/s]\n",
      "Generating dev split: 5 examples [00:00, 76.19 examples/s]\n",
      "2024-12-15:17:58:45,161 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
      "2024-12-15:17:58:45,162 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
      "2024-12-15:17:58:45,162 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
      "2024-12-15:17:58:45,163 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
      "2024-12-15:17:58:45,163 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
      "2024-12-15:17:58:45,164 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
      "2024-12-15:17:58:45,165 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
      "2024-12-15:17:58:45,165 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
      "2024-12-15:17:58:45,166 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
      "2024-12-15:17:58:45,167 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
      "2024-12-15:17:58:45,167 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
      "2024-12-15:17:58:45,168 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
      "2024-12-15:17:58:45,168 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
      "2024-12-15:17:58:45,169 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
      "2024-12-15:17:58:45,170 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
      "2024-12-15:17:58:45,170 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
      "2024-12-15:17:58:45,171 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
      "2024-12-15:17:58:45,171 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
      "2024-12-15:17:58:45,172 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
      "2024-12-15:17:58:45,173 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
      "2024-12-15:17:58:45,173 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
      "2024-12-15:17:58:45,174 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
      "2024-12-15:17:58:45,175 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
      "2024-12-15:17:58:45,175 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
      "2024-12-15:17:58:45,176 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
      "2024-12-15:17:58:45,176 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
      "2024-12-15:17:58:45,177 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
      "2024-12-15:17:58:45,178 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_virology from None to 0\n",
      "2024-12-15:17:58:45,178 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_management from None to 0\n",
      "2024-12-15:17:58:45,179 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
      "2024-12-15:17:58:45,180 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
      "2024-12-15:17:58:45,180 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
      "2024-12-15:17:58:45,181 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
      "2024-12-15:17:58:45,181 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
      "2024-12-15:17:58:45,182 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
      "2024-12-15:17:58:45,183 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
      "2024-12-15:17:58:45,183 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
      "2024-12-15:17:58:45,184 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
      "2024-12-15:17:58:45,184 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
      "2024-12-15:17:58:45,185 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
      "2024-12-15:17:58:45,186 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
      "2024-12-15:17:58:45,186 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
      "2024-12-15:17:58:45,187 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
      "2024-12-15:17:58:45,187 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
      "2024-12-15:17:58:45,188 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
      "2024-12-15:17:58:45,189 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
      "2024-12-15:17:58:45,189 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
      "2024-12-15:17:58:45,190 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
      "2024-12-15:17:58:45,190 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
      "2024-12-15:17:58:45,191 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
      "2024-12-15:17:58:45,192 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
      "2024-12-15:17:58:45,192 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
      "2024-12-15:17:58:45,193 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
      "2024-12-15:17:58:45,194 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
      "2024-12-15:17:58:45,194 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
      "2024-12-15:17:58:45,195 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
      "2024-12-15:17:58:45,196 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
      "2024-12-15:17:58:45,196 WARNING  [evaluator.py:222] Overwriting default num_fewshot of winogrande from None to 0\n",
      "2024-12-15:17:58:45,197 WARNING  [evaluator.py:222] Overwriting default num_fewshot of boolq from None to 0\n",
      "2024-12-15:17:58:45,197 WARNING  [evaluator.py:222] Overwriting default num_fewshot of hellaswag from None to 0\n",
      "2024-12-15:17:58:45,198 WARNING  [evaluator.py:222] Overwriting default num_fewshot of arc_challenge from None to 0\n",
      "2024-12-15:17:58:45,199 WARNING  [evaluator.py:222] Overwriting default num_fewshot of arc_easy from None to 0\n",
      "2024-12-15:17:58:45,199 WARNING  [evaluator.py:222] Overwriting default num_fewshot of piqa from None to 0\n",
      "2024-12-15:17:58:45,219 INFO     [task.py:395] Building contexts for mmlu_moral_scenarios on rank 0...\n",
      "100%|██████████| 895/895 [00:01<00:00, 888.69it/s]\n",
      "2024-12-15:17:58:46,279 INFO     [task.py:395] Building contexts for mmlu_formal_logic on rank 0...\n",
      "100%|██████████| 126/126 [00:00<00:00, 896.28it/s]\n",
      "2024-12-15:17:58:46,428 INFO     [task.py:395] Building contexts for mmlu_high_school_world_history on rank 0...\n",
      "100%|██████████| 237/237 [00:00<00:00, 894.97it/s]\n",
      "2024-12-15:17:58:46,706 INFO     [task.py:395] Building contexts for mmlu_philosophy on rank 0...\n",
      "100%|██████████| 311/311 [00:00<00:00, 1016.21it/s]\n",
      "2024-12-15:17:58:47,028 INFO     [task.py:395] Building contexts for mmlu_moral_disputes on rank 0...\n",
      "100%|██████████| 346/346 [00:00<00:00, 1041.50it/s]\n",
      "2024-12-15:17:58:47,374 INFO     [task.py:395] Building contexts for mmlu_professional_law on rank 0...\n",
      "100%|██████████| 1534/1534 [00:01<00:00, 1051.61it/s]\n",
      "2024-12-15:17:58:48,884 INFO     [task.py:395] Building contexts for mmlu_international_law on rank 0...\n",
      "100%|██████████| 121/121 [00:00<00:00, 1040.00it/s]\n",
      "2024-12-15:17:58:49,006 INFO     [task.py:395] Building contexts for mmlu_high_school_us_history on rank 0...\n",
      "100%|██████████| 204/204 [00:00<00:00, 1044.55it/s]\n",
      "2024-12-15:17:58:49,210 INFO     [task.py:395] Building contexts for mmlu_jurisprudence on rank 0...\n",
      "100%|██████████| 108/108 [00:00<00:00, 1052.23it/s]\n",
      "2024-12-15:17:58:49,317 INFO     [task.py:395] Building contexts for mmlu_high_school_european_history on rank 0...\n",
      "100%|██████████| 165/165 [00:00<00:00, 1044.84it/s]\n",
      "2024-12-15:17:58:49,483 INFO     [task.py:395] Building contexts for mmlu_logical_fallacies on rank 0...\n",
      "100%|██████████| 163/163 [00:00<00:00, 1056.90it/s]\n",
      "2024-12-15:17:58:49,644 INFO     [task.py:395] Building contexts for mmlu_world_religions on rank 0...\n",
      "100%|██████████| 171/171 [00:00<00:00, 1054.46it/s]\n",
      "2024-12-15:17:58:49,813 INFO     [task.py:395] Building contexts for mmlu_prehistory on rank 0...\n",
      "100%|██████████| 324/324 [00:00<00:00, 1055.95it/s]\n",
      "2024-12-15:17:58:50,132 INFO     [task.py:395] Building contexts for mmlu_high_school_psychology on rank 0...\n",
      "100%|██████████| 545/545 [00:00<00:00, 1057.87it/s]\n",
      "2024-12-15:17:58:50,666 INFO     [task.py:395] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
      "100%|██████████| 238/238 [00:00<00:00, 1055.70it/s]\n",
      "2024-12-15:17:58:50,901 INFO     [task.py:395] Building contexts for mmlu_sociology on rank 0...\n",
      "100%|██████████| 201/201 [00:00<00:00, 1051.66it/s]\n",
      "2024-12-15:17:58:51,100 INFO     [task.py:395] Building contexts for mmlu_econometrics on rank 0...\n",
      "100%|██████████| 114/114 [00:00<00:00, 1057.39it/s]\n",
      "2024-12-15:17:58:51,213 INFO     [task.py:395] Building contexts for mmlu_professional_psychology on rank 0...\n",
      "100%|██████████| 612/612 [00:00<00:00, 1058.42it/s]\n",
      "2024-12-15:17:58:51,812 INFO     [task.py:395] Building contexts for mmlu_security_studies on rank 0...\n",
      "100%|██████████| 245/245 [00:00<00:00, 1059.48it/s]\n",
      "2024-12-15:17:58:52,053 INFO     [task.py:395] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
      "100%|██████████| 193/193 [00:00<00:00, 1015.63it/s]\n",
      "2024-12-15:17:58:52,251 INFO     [task.py:395] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 1062.82it/s]\n",
      "2024-12-15:17:58:52,350 INFO     [task.py:395] Building contexts for mmlu_human_sexuality on rank 0...\n",
      "100%|██████████| 131/131 [00:00<00:00, 1057.04it/s]\n",
      "2024-12-15:17:58:52,480 INFO     [task.py:395] Building contexts for mmlu_public_relations on rank 0...\n",
      "100%|██████████| 110/110 [00:00<00:00, 1054.12it/s]\n",
      "2024-12-15:17:58:52,590 INFO     [task.py:395] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
      "100%|██████████| 390/390 [00:00<00:00, 1043.46it/s]\n",
      "2024-12-15:17:58:52,978 INFO     [task.py:395] Building contexts for mmlu_high_school_geography on rank 0...\n",
      "100%|██████████| 198/198 [00:00<00:00, 1048.88it/s]\n",
      "2024-12-15:17:58:53,174 INFO     [task.py:395] Building contexts for mmlu_medical_genetics on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 1043.08it/s]\n",
      "2024-12-15:17:58:53,275 INFO     [task.py:395] Building contexts for mmlu_business_ethics on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 1048.38it/s]\n",
      "2024-12-15:17:58:53,375 INFO     [task.py:395] Building contexts for mmlu_virology on rank 0...\n",
      "100%|██████████| 166/166 [00:00<00:00, 1048.56it/s]\n",
      "2024-12-15:17:58:53,541 INFO     [task.py:395] Building contexts for mmlu_management on rank 0...\n",
      "100%|██████████| 103/103 [00:00<00:00, 1045.31it/s]\n",
      "2024-12-15:17:58:53,644 INFO     [task.py:395] Building contexts for mmlu_professional_accounting on rank 0...\n",
      "100%|██████████| 282/282 [00:00<00:00, 1046.55it/s]\n",
      "2024-12-15:17:58:53,924 INFO     [task.py:395] Building contexts for mmlu_human_aging on rank 0...\n",
      "100%|██████████| 223/223 [00:00<00:00, 1052.18it/s]\n",
      "2024-12-15:17:58:54,145 INFO     [task.py:395] Building contexts for mmlu_nutrition on rank 0...\n",
      "100%|██████████| 306/306 [00:00<00:00, 1056.68it/s]\n",
      "2024-12-15:17:58:54,446 INFO     [task.py:395] Building contexts for mmlu_global_facts on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 1057.32it/s]\n",
      "2024-12-15:17:58:54,546 INFO     [task.py:395] Building contexts for mmlu_marketing on rank 0...\n",
      "100%|██████████| 234/234 [00:00<00:00, 1037.66it/s]\n",
      "2024-12-15:17:58:54,781 INFO     [task.py:395] Building contexts for mmlu_miscellaneous on rank 0...\n",
      "100%|██████████| 783/783 [00:00<00:00, 1047.49it/s]\n",
      "2024-12-15:17:58:55,556 INFO     [task.py:395] Building contexts for mmlu_professional_medicine on rank 0...\n",
      "100%|██████████| 272/272 [00:00<00:00, 535.29it/s]\n",
      "2024-12-15:17:58:56,074 INFO     [task.py:395] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
      "100%|██████████| 265/265 [00:00<00:00, 1054.15it/s]\n",
      "2024-12-15:17:58:56,336 INFO     [task.py:395] Building contexts for mmlu_college_medicine on rank 0...\n",
      "100%|██████████| 173/173 [00:00<00:00, 1060.18it/s]\n",
      "2024-12-15:17:58:56,506 INFO     [task.py:395] Building contexts for mmlu_college_mathematics on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 1063.15it/s]\n",
      "2024-12-15:17:58:56,605 INFO     [task.py:395] Building contexts for mmlu_machine_learning on rank 0...\n",
      "100%|██████████| 112/112 [00:00<00:00, 1059.74it/s]\n",
      "2024-12-15:17:58:56,716 INFO     [task.py:395] Building contexts for mmlu_astronomy on rank 0...\n",
      "100%|██████████| 152/152 [00:00<00:00, 1059.58it/s]\n",
      "2024-12-15:17:58:56,866 INFO     [task.py:395] Building contexts for mmlu_anatomy on rank 0...\n",
      "100%|██████████| 135/135 [00:00<00:00, 985.65it/s] \n",
      "2024-12-15:17:58:57,009 INFO     [task.py:395] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 905.90it/s]\n",
      "2024-12-15:17:58:57,127 INFO     [task.py:395] Building contexts for mmlu_abstract_algebra on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 896.73it/s]\n",
      "2024-12-15:17:58:57,246 INFO     [task.py:395] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
      "100%|██████████| 203/203 [00:00<00:00, 904.26it/s]\n",
      "2024-12-15:17:58:57,481 INFO     [task.py:395] Building contexts for mmlu_college_biology on rank 0...\n",
      "100%|██████████| 144/144 [00:00<00:00, 904.72it/s]\n",
      "2024-12-15:17:58:57,649 INFO     [task.py:395] Building contexts for mmlu_conceptual_physics on rank 0...\n",
      "100%|██████████| 235/235 [00:00<00:00, 906.81it/s]\n",
      "2024-12-15:17:58:57,921 INFO     [task.py:395] Building contexts for mmlu_high_school_statistics on rank 0...\n",
      "100%|██████████| 216/216 [00:00<00:00, 907.66it/s]\n",
      "2024-12-15:17:58:58,170 INFO     [task.py:395] Building contexts for mmlu_computer_security on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 902.74it/s]\n",
      "2024-12-15:17:58:58,288 INFO     [task.py:395] Building contexts for mmlu_electrical_engineering on rank 0...\n",
      "100%|██████████| 145/145 [00:00<00:00, 907.15it/s]\n",
      "2024-12-15:17:58:58,458 INFO     [task.py:395] Building contexts for mmlu_high_school_biology on rank 0...\n",
      "100%|██████████| 310/310 [00:00<00:00, 1002.66it/s]\n",
      "2024-12-15:17:58:58,782 INFO     [task.py:395] Building contexts for mmlu_college_computer_science on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 1054.39it/s]\n",
      "2024-12-15:17:58:58,883 INFO     [task.py:395] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
      "100%|██████████| 270/270 [00:00<00:00, 1050.98it/s]\n",
      "2024-12-15:17:58:59,152 INFO     [task.py:395] Building contexts for mmlu_college_physics on rank 0...\n",
      "100%|██████████| 102/102 [00:00<00:00, 1059.65it/s]\n",
      "2024-12-15:17:58:59,255 INFO     [task.py:395] Building contexts for mmlu_high_school_physics on rank 0...\n",
      "100%|██████████| 151/151 [00:00<00:00, 1047.28it/s]\n",
      "2024-12-15:17:58:59,408 INFO     [task.py:395] Building contexts for mmlu_college_chemistry on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 1060.58it/s]\n",
      "2024-12-15:17:58:59,509 INFO     [task.py:395] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
      "100%|██████████| 378/378 [00:00<00:00, 1052.09it/s]\n",
      "2024-12-15:17:58:59,884 INFO     [task.py:395] Building contexts for winogrande on rank 0...\n",
      "100%|██████████| 1267/1267 [00:00<00:00, 160948.06it/s]\n",
      "2024-12-15:17:58:59,927 INFO     [task.py:395] Building contexts for boolq on rank 0...\n",
      "100%|██████████| 3270/3270 [00:00<00:00, 3410.65it/s]\n",
      "2024-12-15:17:59:00,975 INFO     [task.py:395] Building contexts for hellaswag on rank 0...\n",
      "100%|██████████| 10042/10042 [00:02<00:00, 4144.00it/s]\n",
      "2024-12-15:17:59:04,226 INFO     [task.py:395] Building contexts for arc_challenge on rank 0...\n",
      "100%|██████████| 1172/1172 [00:00<00:00, 1842.84it/s]\n",
      "2024-12-15:17:59:04,928 INFO     [task.py:395] Building contexts for arc_easy on rank 0...\n",
      "100%|██████████| 2376/2376 [00:01<00:00, 1920.19it/s]\n",
      "2024-12-15:17:59:06,265 INFO     [task.py:395] Building contexts for piqa on rank 0...\n",
      "100%|██████████| 1838/1838 [00:00<00:00, 1863.83it/s]\n",
      "2024-12-15:17:59:07,302 INFO     [evaluator.py:362] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|██████████| 123274/123274 [42:42<00:00, 48.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                 Tasks                 |Version|Filter|n-shot| Metric |Value |   |Stderr|\n",
      "|---------------------------------------|-------|------|-----:|--------|-----:|---|-----:|\n",
      "|mmlu                                   |N/A    |none  |     0|acc     |0.3586|±  |0.0040|\n",
      "| - humanities                          |N/A    |none  |     0|acc     |0.3445|±  |0.0068|\n",
      "|  - formal_logic                       |      0|none  |     0|acc     |0.3016|±  |0.0410|\n",
      "|  - high_school_european_history       |      0|none  |     0|acc     |0.4364|±  |0.0387|\n",
      "|  - high_school_us_history             |      0|none  |     0|acc     |0.4118|±  |0.0345|\n",
      "|  - high_school_world_history          |      0|none  |     0|acc     |0.4557|±  |0.0324|\n",
      "|  - international_law                  |      0|none  |     0|acc     |0.5041|±  |0.0456|\n",
      "|  - jurisprudence                      |      0|none  |     0|acc     |0.4444|±  |0.0480|\n",
      "|  - logical_fallacies                  |      0|none  |     0|acc     |0.3620|±  |0.0378|\n",
      "|  - moral_disputes                     |      0|none  |     0|acc     |0.3613|±  |0.0259|\n",
      "|  - moral_scenarios                    |      0|none  |     0|acc     |0.2380|±  |0.0142|\n",
      "|  - philosophy                         |      0|none  |     0|acc     |0.4341|±  |0.0282|\n",
      "|  - prehistory                         |      0|none  |     0|acc     |0.4043|±  |0.0273|\n",
      "|  - professional_law                   |      0|none  |     0|acc     |0.3025|±  |0.0117|\n",
      "|  - world_religions                    |      0|none  |     0|acc     |0.4854|±  |0.0383|\n",
      "| - other                               |N/A    |none  |     0|acc     |0.3791|±  |0.0087|\n",
      "|  - business_ethics                    |      0|none  |     0|acc     |0.2800|±  |0.0451|\n",
      "|  - clinical_knowledge                 |      0|none  |     0|acc     |0.3925|±  |0.0301|\n",
      "|  - college_medicine                   |      0|none  |     0|acc     |0.2948|±  |0.0348|\n",
      "|  - global_facts                       |      0|none  |     0|acc     |0.2800|±  |0.0451|\n",
      "|  - human_aging                        |      0|none  |     0|acc     |0.2870|±  |0.0304|\n",
      "|  - management                         |      0|none  |     0|acc     |0.4660|±  |0.0494|\n",
      "|  - marketing                          |      0|none  |     0|acc     |0.4060|±  |0.0322|\n",
      "|  - medical_genetics                   |      0|none  |     0|acc     |0.3900|±  |0.0490|\n",
      "|  - miscellaneous                      |      0|none  |     0|acc     |0.4483|±  |0.0178|\n",
      "|  - nutrition                          |      0|none  |     0|acc     |0.3922|±  |0.0280|\n",
      "|  - professional_accounting            |      0|none  |     0|acc     |0.2943|±  |0.0272|\n",
      "|  - professional_medicine              |      0|none  |     0|acc     |0.3676|±  |0.0293|\n",
      "|  - virology                           |      0|none  |     0|acc     |0.4036|±  |0.0382|\n",
      "| - social_sciences                     |N/A    |none  |     0|acc     |0.4004|±  |0.0088|\n",
      "|  - econometrics                       |      0|none  |     0|acc     |0.3246|±  |0.0440|\n",
      "|  - high_school_geography              |      0|none  |     0|acc     |0.3586|±  |0.0342|\n",
      "|  - high_school_government_and_politics|      0|none  |     0|acc     |0.5285|±  |0.0360|\n",
      "|  - high_school_macroeconomics         |      0|none  |     0|acc     |0.3564|±  |0.0243|\n",
      "|  - high_school_microeconomics         |      0|none  |     0|acc     |0.2899|±  |0.0295|\n",
      "|  - high_school_psychology             |      0|none  |     0|acc     |0.4587|±  |0.0214|\n",
      "|  - human_sexuality                    |      0|none  |     0|acc     |0.4046|±  |0.0430|\n",
      "|  - professional_psychology            |      0|none  |     0|acc     |0.3611|±  |0.0194|\n",
      "|  - public_relations                   |      0|none  |     0|acc     |0.4091|±  |0.0471|\n",
      "|  - security_studies                   |      0|none  |     0|acc     |0.3755|±  |0.0310|\n",
      "|  - sociology                          |      0|none  |     0|acc     |0.5174|±  |0.0353|\n",
      "|  - us_foreign_policy                  |      0|none  |     0|acc     |0.4900|±  |0.0502|\n",
      "| - stem                                |N/A    |none  |     0|acc     |0.3184|±  |0.0082|\n",
      "|  - abstract_algebra                   |      0|none  |     0|acc     |0.2400|±  |0.0429|\n",
      "|  - anatomy                            |      0|none  |     0|acc     |0.3556|±  |0.0414|\n",
      "|  - astronomy                          |      0|none  |     0|acc     |0.3750|±  |0.0394|\n",
      "|  - college_biology                    |      0|none  |     0|acc     |0.3333|±  |0.0394|\n",
      "|  - college_chemistry                  |      0|none  |     0|acc     |0.2300|±  |0.0423|\n",
      "|  - college_computer_science           |      0|none  |     0|acc     |0.2900|±  |0.0456|\n",
      "|  - college_mathematics                |      0|none  |     0|acc     |0.3400|±  |0.0476|\n",
      "|  - college_physics                    |      0|none  |     0|acc     |0.1961|±  |0.0395|\n",
      "|  - computer_security                  |      0|none  |     0|acc     |0.4800|±  |0.0502|\n",
      "|  - conceptual_physics                 |      0|none  |     0|acc     |0.3957|±  |0.0320|\n",
      "|  - electrical_engineering             |      0|none  |     0|acc     |0.3103|±  |0.0386|\n",
      "|  - elementary_mathematics             |      0|none  |     0|acc     |0.2698|±  |0.0229|\n",
      "|  - high_school_biology                |      0|none  |     0|acc     |0.4226|±  |0.0281|\n",
      "|  - high_school_chemistry              |      0|none  |     0|acc     |0.3153|±  |0.0327|\n",
      "|  - high_school_computer_science       |      0|none  |     0|acc     |0.4000|±  |0.0492|\n",
      "|  - high_school_mathematics            |      0|none  |     0|acc     |0.2185|±  |0.0252|\n",
      "|  - high_school_physics                |      0|none  |     0|acc     |0.2781|±  |0.0366|\n",
      "|  - high_school_statistics             |      0|none  |     0|acc     |0.2731|±  |0.0304|\n",
      "|  - machine_learning                   |      0|none  |     0|acc     |0.3393|±  |0.0449|\n",
      "|winogrande                             |      1|none  |     0|acc     |0.6480|±  |0.0134|\n",
      "|boolq                                  |      2|none  |     0|acc     |0.7514|±  |0.0076|\n",
      "|hellaswag                              |      1|none  |     0|acc     |0.5165|±  |0.0050|\n",
      "|                                       |       |none  |     0|acc_norm|0.6841|±  |0.0046|\n",
      "|arc_challenge                          |      1|none  |     0|acc     |0.3669|±  |0.0141|\n",
      "|                                       |       |none  |     0|acc_norm|0.3925|±  |0.0143|\n",
      "|arc_easy                               |      1|none  |     0|acc     |0.6965|±  |0.0094|\n",
      "|                                       |       |none  |     0|acc_norm|0.6570|±  |0.0097|\n",
      "|piqa                                   |      1|none  |     0|acc     |0.7601|±  |0.0100|\n",
      "|                                       |       |none  |     0|acc_norm|0.7633|±  |0.0099|\n",
      "\n",
      "Average Acc: 58.54%\n"
     ]
    }
   ],
   "source": [
    "# Test Zero_shot\n",
    "import lm_eval\n",
    "from lm_eval.models.huggingface import HFLM\n",
    "from lm_eval.utils import make_table\n",
    "eval_tasks = 'piqa,arc_easy,arc_challenge,hellaswag,boolq,winogrande,mmlu'\n",
    "task_list = eval_tasks.split(',')\n",
    "model = HFLM(pretrained=model, batch_size=8)\n",
    "task_manager = lm_eval.tasks.TaskManager()\n",
    "results = lm_eval.simple_evaluate(\n",
    "        model=model,\n",
    "        tasks=task_list,\n",
    "        num_fewshot=0,\n",
    "        task_manager=task_manager,\n",
    "        )\n",
    "print(make_table(results))\n",
    "total_acc = 0\n",
    "for task in task_list:\n",
    "    total_acc += results['results'][task]['acc,none']\n",
    "print(f'Average Acc: {total_acc/len(task_list)*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frm-ptq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
