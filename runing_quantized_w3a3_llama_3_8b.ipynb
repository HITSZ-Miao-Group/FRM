{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runing LLaMA-3-8B W3A3 quantized model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the prebuilt quantized model:\n",
    "We have provide the prebuilt quantized model on Huggingface. In order to download the large weights, we'll have to use git lfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! conda install git git-lfs\n",
    "! git lfs install\n",
    "\n",
    "# download LLaMA-3-8b-w3a3 quantization\n",
    "! git clone git clone https://huggingface.co/FRM-PTQ/Llama-3-8b-w3a3-frm-ptq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"http_proxy\"] = \"http://localhost:7890\"\n",
    "os.environ[\"https_proxy\"] = \"http://localhost:7890\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/frm-ptq/lib/python3.11/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from accelerate import infer_auto_device_map, dispatch_model\n",
    "import torch\n",
    "from datautils import get_loaders, test_ppl\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, tokenizer):\n",
    "    '''\n",
    "    Note: evaluation simply move model to single GPU. \n",
    "    Therefor, to evaluate large model such as Llama-2-70B on single A100-80GB,\n",
    "    please activate '--real_quant'.\n",
    "    '''\n",
    "    # import pdb;pdb.set_trace()\n",
    "    block_class_name = model.model.layers[0].__class__.__name__\n",
    "    device_map = infer_auto_device_map(model, max_memory={i: '40GB' for i in range(torch.cuda.device_count())}, no_split_module_classes=[block_class_name])\n",
    "    model = dispatch_model(model, device_map=device_map)\n",
    "    results = {}\n",
    "\n",
    "    datasets = [\"wikitext2\", \"c4\"]\n",
    "    ppl_results = test_ppl(model, tokenizer, datasets, 2048)\n",
    "    for dataset in ppl_results:\n",
    "        print(f'{dataset} perplexity: {ppl_results[dataset]:.2f}')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading quantized model from /root/code_z/FRM/output/block_ap_models/Llama-3-8b-w3a3g128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 86.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-computed quantized weights...\n",
      "Loading pre-computed quantized weights Successfully\n",
      "memory footprint after loading quantized model: 4.78GiB\n",
      "get_wikitext2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [01:01<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikitext2:10.751235961914062\n",
      "get_c4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [01:43<00:00,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c4:15.501581192016602\n",
      "wikitext2 perplexity: 10.75\n",
      "c4 perplexity: 15.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from quantize.int_linear_real import load_quantized_model\n",
    "from accelerate import infer_auto_device_map, dispatch_model\n",
    "import torch\n",
    "\n",
    "model_path = './Llama-3-8b-w3a3g128-frm-ptq'\n",
    "wbits = 3\n",
    "abits = 3\n",
    "group_size = 128\n",
    "use_act_quant = True\n",
    "sensitive_group = [10, 15, 16, 8, 13, 31, 1, 0]\n",
    "robust_group = [23, 24, 22, 25, 26, 3]\n",
    "model, tokenizer = load_quantized_model(model_path=model_path, wbits=wbits, abits=abits,group_size=group_size, use_act_quant=use_act_quant, sensitive_group=sensitive_group, robust_group=robust_group)\n",
    "print(f\"memory footprint after loading quantized model: {torch.cuda.max_memory_allocated('cuda') / 1024**3:.2f}GiB\")\n",
    "\n",
    "# Test PPL\n",
    "evaluate(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09:17:31:34,556 WARNING  [loading.py:546] Using the latest cached version of the module from /root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--exact_match/9d3b67e0c429cd7460b2b05aab53419b48eea369b73e1d9f185a56ca90c373d4 (last modified on Mon Jul 29 13:20:50 2024) since it couldn't be found locally at evaluate-metric--exact_match, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:31:34,659 WARNING  [huggingface.py:118] `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "2025-05-09:17:31:35,739 WARNING  [huggingface.py:337] Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n",
      "2025-05-09:17:31:40,092 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "/root/miniconda3/envs/frm-ptq/lib/python3.11/site-packages/datasets/load.py:1461: FutureWarning: The repository for piqa contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/piqa\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/frm-ptq/lib/python3.11/site-packages/datasets/load.py:1461: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "2025-05-09:17:32:30,291 WARNING  [task.py:763] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2025-05-09:17:32:30,294 WARNING  [task.py:775] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "/root/miniconda3/envs/frm-ptq/lib/python3.11/site-packages/datasets/load.py:1461: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/frm-ptq/lib/python3.11/site-packages/datasets/load.py:1461: FutureWarning: The repository for winogrande contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/winogrande\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/frm-ptq/lib/python3.11/site-packages/datasets/load.py:1461: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:35:14,740 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:35:29,560 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:35:44,787 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:35:59,112 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:36:13,517 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:36:27,918 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:36:42,281 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:36:56,677 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:37:11,042 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:37:25,820 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:37:39,804 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:37:54,600 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:38:08,186 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:38:22,564 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:38:36,477 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:38:50,809 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:39:05,601 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:39:19,166 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:39:33,931 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:39:48,737 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:40:03,097 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:40:17,471 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:40:32,285 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:40:45,791 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:41:02,337 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:41:17,257 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:42:33,215 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:42:38,251 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:42:43,286 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:42:48,321 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:42:53,353 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:42:58,388 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:43:03,419 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:43:08,452 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:43:13,486 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:43:18,518 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:43:23,549 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:43:28,581 WARNING  [load.py:1569] Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hails--mmlu_no_train/b7d5f7f21003c21be079f11495ee011332b980bd1cd7e70cc740e8c079e5bda2 (last modified on Wed Oct 23 10:51:38 2024) since it couldn't be found locally at hails/mmlu_no_train, or remotely on the Hugging Face Hub.\n",
      "2025-05-09:17:43:28,605 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
      "2025-05-09:17:43:28,606 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
      "2025-05-09:17:43:28,607 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
      "2025-05-09:17:43:28,608 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
      "2025-05-09:17:43:28,608 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
      "2025-05-09:17:43:28,609 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
      "2025-05-09:17:43:28,609 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
      "2025-05-09:17:43:28,610 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
      "2025-05-09:17:43:28,610 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
      "2025-05-09:17:43:28,611 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
      "2025-05-09:17:43:28,611 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
      "2025-05-09:17:43:28,612 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
      "2025-05-09:17:43:28,612 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
      "2025-05-09:17:43:28,613 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
      "2025-05-09:17:43:28,614 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
      "2025-05-09:17:43:28,614 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
      "2025-05-09:17:43:28,614 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
      "2025-05-09:17:43:28,614 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
      "2025-05-09:17:43:28,615 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
      "2025-05-09:17:43:28,615 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
      "2025-05-09:17:43:28,616 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
      "2025-05-09:17:43:28,616 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
      "2025-05-09:17:43:28,617 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
      "2025-05-09:17:43:28,617 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
      "2025-05-09:17:43:28,618 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
      "2025-05-09:17:43:28,618 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
      "2025-05-09:17:43:28,619 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
      "2025-05-09:17:43:28,620 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
      "2025-05-09:17:43:28,620 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
      "2025-05-09:17:43:28,620 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
      "2025-05-09:17:43:28,621 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
      "2025-05-09:17:43:28,621 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_management from None to 0\n",
      "2025-05-09:17:43:28,622 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
      "2025-05-09:17:43:28,622 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
      "2025-05-09:17:43:28,622 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
      "2025-05-09:17:43:28,622 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_virology from None to 0\n",
      "2025-05-09:17:43:28,623 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
      "2025-05-09:17:43:28,623 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
      "2025-05-09:17:43:28,624 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
      "2025-05-09:17:43:28,624 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
      "2025-05-09:17:43:28,624 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
      "2025-05-09:17:43:28,625 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
      "2025-05-09:17:43:28,625 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
      "2025-05-09:17:43:28,625 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
      "2025-05-09:17:43:28,625 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
      "2025-05-09:17:43:28,626 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
      "2025-05-09:17:43:28,626 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
      "2025-05-09:17:43:28,626 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
      "2025-05-09:17:43:28,627 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
      "2025-05-09:17:43:28,628 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
      "2025-05-09:17:43:28,628 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
      "2025-05-09:17:43:28,628 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
      "2025-05-09:17:43:28,628 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
      "2025-05-09:17:43:28,629 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
      "2025-05-09:17:43:28,629 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
      "2025-05-09:17:43:28,629 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
      "2025-05-09:17:43:28,629 WARNING  [evaluator.py:222] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
      "2025-05-09:17:43:28,630 WARNING  [evaluator.py:222] Overwriting default num_fewshot of winogrande from None to 0\n",
      "2025-05-09:17:43:28,630 WARNING  [evaluator.py:222] Overwriting default num_fewshot of boolq from None to 0\n",
      "2025-05-09:17:43:28,630 WARNING  [evaluator.py:222] Overwriting default num_fewshot of hellaswag from None to 0\n",
      "2025-05-09:17:43:28,631 WARNING  [evaluator.py:222] Overwriting default num_fewshot of arc_challenge from None to 0\n",
      "2025-05-09:17:43:28,631 WARNING  [evaluator.py:222] Overwriting default num_fewshot of arc_easy from None to 0\n",
      "2025-05-09:17:43:28,631 WARNING  [evaluator.py:222] Overwriting default num_fewshot of piqa from None to 0\n",
      "2025-05-09:17:43:28,641 INFO     [task.py:395] Building contexts for mmlu_high_school_world_history on rank 0...\n",
      "100%|██████████| 237/237 [00:00<00:00, 703.18it/s]\n",
      "2025-05-09:17:43:28,995 INFO     [task.py:395] Building contexts for mmlu_moral_disputes on rank 0...\n",
      "100%|██████████| 346/346 [00:00<00:00, 716.42it/s]\n",
      "2025-05-09:17:43:29,498 INFO     [task.py:395] Building contexts for mmlu_prehistory on rank 0...\n",
      "100%|██████████| 324/324 [00:00<00:00, 717.55it/s]\n",
      "2025-05-09:17:43:29,968 INFO     [task.py:395] Building contexts for mmlu_high_school_us_history on rank 0...\n",
      "100%|██████████| 204/204 [00:00<00:00, 696.90it/s]\n",
      "2025-05-09:17:43:30,278 INFO     [task.py:395] Building contexts for mmlu_moral_scenarios on rank 0...\n",
      "100%|██████████| 895/895 [00:01<00:00, 702.87it/s]\n",
      "2025-05-09:17:43:31,597 INFO     [task.py:395] Building contexts for mmlu_formal_logic on rank 0...\n",
      "100%|██████████| 126/126 [00:00<00:00, 707.39it/s]\n",
      "2025-05-09:17:43:31,786 INFO     [task.py:395] Building contexts for mmlu_professional_law on rank 0...\n",
      "100%|██████████| 1534/1534 [00:02<00:00, 696.61it/s]\n",
      "2025-05-09:17:43:34,070 INFO     [task.py:395] Building contexts for mmlu_high_school_european_history on rank 0...\n",
      "100%|██████████| 165/165 [00:00<00:00, 709.63it/s]\n",
      "2025-05-09:17:43:34,316 INFO     [task.py:395] Building contexts for mmlu_jurisprudence on rank 0...\n",
      "100%|██████████| 108/108 [00:00<00:00, 712.69it/s]\n",
      "2025-05-09:17:43:34,476 INFO     [task.py:395] Building contexts for mmlu_logical_fallacies on rank 0...\n",
      "100%|██████████| 163/163 [00:00<00:00, 716.00it/s]\n",
      "2025-05-09:17:43:34,715 INFO     [task.py:395] Building contexts for mmlu_world_religions on rank 0...\n",
      "100%|██████████| 171/171 [00:00<00:00, 722.61it/s]\n",
      "2025-05-09:17:43:34,963 INFO     [task.py:395] Building contexts for mmlu_philosophy on rank 0...\n",
      "100%|██████████| 311/311 [00:00<00:00, 691.68it/s]\n",
      "2025-05-09:17:43:35,431 INFO     [task.py:395] Building contexts for mmlu_international_law on rank 0...\n",
      "100%|██████████| 121/121 [00:00<00:00, 701.96it/s]\n",
      "2025-05-09:17:43:35,612 INFO     [task.py:395] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 652.08it/s]\n",
      "2025-05-09:17:43:35,775 INFO     [task.py:395] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
      "100%|██████████| 238/238 [00:00<00:00, 300.75it/s]\n",
      "2025-05-09:17:43:36,582 INFO     [task.py:395] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
      "100%|██████████| 193/193 [00:00<00:00, 674.18it/s]\n",
      "2025-05-09:17:43:36,880 INFO     [task.py:395] Building contexts for mmlu_econometrics on rank 0...\n",
      "100%|██████████| 114/114 [00:00<00:00, 659.14it/s]\n",
      "2025-05-09:17:43:37,062 INFO     [task.py:395] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
      "100%|██████████| 390/390 [00:00<00:00, 690.56it/s]\n",
      "2025-05-09:17:43:37,649 INFO     [task.py:395] Building contexts for mmlu_public_relations on rank 0...\n",
      "100%|██████████| 110/110 [00:00<00:00, 714.80it/s]\n",
      "2025-05-09:17:43:37,811 INFO     [task.py:395] Building contexts for mmlu_high_school_geography on rank 0...\n",
      "100%|██████████| 198/198 [00:00<00:00, 703.24it/s]\n",
      "2025-05-09:17:43:38,105 INFO     [task.py:395] Building contexts for mmlu_professional_psychology on rank 0...\n",
      "100%|██████████| 612/612 [00:00<00:00, 713.64it/s]\n",
      "2025-05-09:17:43:38,995 INFO     [task.py:395] Building contexts for mmlu_human_sexuality on rank 0...\n",
      "100%|██████████| 131/131 [00:00<00:00, 702.64it/s]\n",
      "2025-05-09:17:43:39,195 INFO     [task.py:395] Building contexts for mmlu_sociology on rank 0...\n",
      "100%|██████████| 201/201 [00:00<00:00, 620.62it/s]\n",
      "2025-05-09:17:43:39,533 INFO     [task.py:395] Building contexts for mmlu_security_studies on rank 0...\n",
      "100%|██████████| 245/245 [00:00<00:00, 714.27it/s]\n",
      "2025-05-09:17:43:39,890 INFO     [task.py:395] Building contexts for mmlu_high_school_psychology on rank 0...\n",
      "100%|██████████| 545/545 [00:00<00:00, 720.57it/s]\n",
      "2025-05-09:17:43:40,676 INFO     [task.py:395] Building contexts for mmlu_medical_genetics on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 719.69it/s]\n",
      "2025-05-09:17:43:40,822 INFO     [task.py:395] Building contexts for mmlu_marketing on rank 0...\n",
      "100%|██████████| 234/234 [00:00<00:00, 714.50it/s]\n",
      "2025-05-09:17:43:41,163 INFO     [task.py:395] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
      "100%|██████████| 265/265 [00:00<00:00, 715.18it/s]\n",
      "2025-05-09:17:43:41,548 INFO     [task.py:395] Building contexts for mmlu_human_aging on rank 0...\n",
      "100%|██████████| 223/223 [00:00<00:00, 709.97it/s]\n",
      "2025-05-09:17:43:41,876 INFO     [task.py:395] Building contexts for mmlu_nutrition on rank 0...\n",
      "100%|██████████| 306/306 [00:00<00:00, 700.89it/s]\n",
      "2025-05-09:17:43:42,331 INFO     [task.py:395] Building contexts for mmlu_college_medicine on rank 0...\n",
      "100%|██████████| 173/173 [00:00<00:00, 711.98it/s]\n",
      "2025-05-09:17:43:42,585 INFO     [task.py:395] Building contexts for mmlu_management on rank 0...\n",
      "100%|██████████| 103/103 [00:00<00:00, 724.40it/s]\n",
      "2025-05-09:17:43:42,734 INFO     [task.py:395] Building contexts for mmlu_professional_medicine on rank 0...\n",
      "100%|██████████| 272/272 [00:00<00:00, 714.71it/s]\n",
      "2025-05-09:17:43:43,131 INFO     [task.py:395] Building contexts for mmlu_professional_accounting on rank 0...\n",
      "100%|██████████| 282/282 [00:00<00:00, 725.91it/s]\n",
      "2025-05-09:17:43:43,542 INFO     [task.py:395] Building contexts for mmlu_global_facts on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 704.40it/s]\n",
      "2025-05-09:17:43:43,693 INFO     [task.py:395] Building contexts for mmlu_virology on rank 0...\n",
      "100%|██████████| 166/166 [00:00<00:00, 701.81it/s]\n",
      "2025-05-09:17:43:43,940 INFO     [task.py:395] Building contexts for mmlu_miscellaneous on rank 0...\n",
      "100%|██████████| 783/783 [00:01<00:00, 709.65it/s]\n",
      "2025-05-09:17:43:45,082 INFO     [task.py:395] Building contexts for mmlu_business_ethics on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 725.73it/s]\n",
      "2025-05-09:17:43:45,226 INFO     [task.py:395] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
      "100%|██████████| 203/203 [00:00<00:00, 673.06it/s]\n",
      "2025-05-09:17:43:45,540 INFO     [task.py:395] Building contexts for mmlu_high_school_biology on rank 0...\n",
      "100%|██████████| 310/310 [00:00<00:00, 712.06it/s]\n",
      "2025-05-09:17:43:45,993 INFO     [task.py:395] Building contexts for mmlu_college_physics on rank 0...\n",
      "100%|██████████| 102/102 [00:00<00:00, 717.69it/s]\n",
      "2025-05-09:17:43:46,143 INFO     [task.py:395] Building contexts for mmlu_electrical_engineering on rank 0...\n",
      "100%|██████████| 145/145 [00:00<00:00, 675.38it/s]\n",
      "2025-05-09:17:43:46,368 INFO     [task.py:395] Building contexts for mmlu_high_school_physics on rank 0...\n",
      "100%|██████████| 151/151 [00:00<00:00, 697.71it/s]\n",
      "2025-05-09:17:43:46,595 INFO     [task.py:395] Building contexts for mmlu_college_computer_science on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 721.32it/s]\n",
      "2025-05-09:17:43:46,741 INFO     [task.py:395] Building contexts for mmlu_college_biology on rank 0...\n",
      "100%|██████████| 144/144 [00:00<00:00, 726.24it/s]\n",
      "2025-05-09:17:43:46,950 INFO     [task.py:395] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
      "100%|██████████| 378/378 [00:00<00:00, 717.10it/s]\n",
      "2025-05-09:17:43:47,498 INFO     [task.py:395] Building contexts for mmlu_anatomy on rank 0...\n",
      "100%|██████████| 135/135 [00:00<00:00, 721.64it/s]\n",
      "2025-05-09:17:43:47,695 INFO     [task.py:395] Building contexts for mmlu_college_chemistry on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 719.11it/s]\n",
      "2025-05-09:17:43:47,842 INFO     [task.py:395] Building contexts for mmlu_machine_learning on rank 0...\n",
      "100%|██████████| 112/112 [00:00<00:00, 679.65it/s]\n",
      "2025-05-09:17:43:48,015 INFO     [task.py:395] Building contexts for mmlu_college_mathematics on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 716.74it/s]\n",
      "2025-05-09:17:43:48,162 INFO     [task.py:395] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
      "100%|██████████| 270/270 [00:00<00:00, 720.85it/s]\n",
      "2025-05-09:17:43:48,553 INFO     [task.py:395] Building contexts for mmlu_high_school_statistics on rank 0...\n",
      "100%|██████████| 216/216 [00:00<00:00, 692.53it/s]\n",
      "2025-05-09:17:43:48,878 INFO     [task.py:395] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 708.76it/s]\n",
      "2025-05-09:17:43:49,027 INFO     [task.py:395] Building contexts for mmlu_astronomy on rank 0...\n",
      "100%|██████████| 152/152 [00:00<00:00, 692.47it/s]\n",
      "2025-05-09:17:43:49,256 INFO     [task.py:395] Building contexts for mmlu_conceptual_physics on rank 0...\n",
      "100%|██████████| 235/235 [00:00<00:00, 716.72it/s]\n",
      "2025-05-09:17:43:49,598 INFO     [task.py:395] Building contexts for mmlu_computer_security on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 709.32it/s]\n",
      "2025-05-09:17:43:49,747 INFO     [task.py:395] Building contexts for mmlu_abstract_algebra on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 719.13it/s]\n",
      "2025-05-09:17:43:49,894 INFO     [task.py:395] Building contexts for winogrande on rank 0...\n",
      "100%|██████████| 1267/1267 [00:00<00:00, 100097.63it/s]\n",
      "2025-05-09:17:43:49,956 INFO     [task.py:395] Building contexts for boolq on rank 0...\n",
      "100%|██████████| 3270/3270 [00:01<00:00, 2352.01it/s]\n",
      "2025-05-09:17:43:51,475 INFO     [task.py:395] Building contexts for hellaswag on rank 0...\n",
      "100%|██████████| 10042/10042 [00:02<00:00, 3565.25it/s]\n",
      "2025-05-09:17:43:55,859 INFO     [task.py:395] Building contexts for arc_challenge on rank 0...\n",
      "100%|██████████| 1172/1172 [00:00<00:00, 1442.61it/s]\n",
      "2025-05-09:17:43:56,738 INFO     [task.py:395] Building contexts for arc_easy on rank 0...\n",
      "100%|██████████| 2376/2376 [00:01<00:00, 1413.73it/s]\n",
      "2025-05-09:17:43:58,558 INFO     [task.py:395] Building contexts for piqa on rank 0...\n",
      "100%|██████████| 1838/1838 [00:01<00:00, 1491.60it/s]\n",
      "2025-05-09:17:43:59,853 INFO     [evaluator.py:362] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|██████████| 123274/123274 [30:22<00:00, 67.63it/s] \n",
      "fatal: not a git repository (or any parent up to mount point /)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                 Tasks                 |Version|Filter|n-shot| Metric |Value |   |Stderr|\n",
      "|---------------------------------------|-------|------|-----:|--------|-----:|---|-----:|\n",
      "|mmlu                                   |N/A    |none  |     0|acc     |0.3631|±  |0.0040|\n",
      "| - humanities                          |N/A    |none  |     0|acc     |0.3403|±  |0.0068|\n",
      "|  - formal_logic                       |      0|none  |     0|acc     |0.2937|±  |0.0407|\n",
      "|  - high_school_european_history       |      0|none  |     0|acc     |0.4061|±  |0.0383|\n",
      "|  - high_school_us_history             |      0|none  |     0|acc     |0.4363|±  |0.0348|\n",
      "|  - high_school_world_history          |      0|none  |     0|acc     |0.5021|±  |0.0325|\n",
      "|  - international_law                  |      0|none  |     0|acc     |0.3884|±  |0.0445|\n",
      "|  - jurisprudence                      |      0|none  |     0|acc     |0.3796|±  |0.0469|\n",
      "|  - logical_fallacies                  |      0|none  |     0|acc     |0.3374|±  |0.0371|\n",
      "|  - moral_disputes                     |      0|none  |     0|acc     |0.3526|±  |0.0257|\n",
      "|  - moral_scenarios                    |      0|none  |     0|acc     |0.2492|±  |0.0145|\n",
      "|  - philosophy                         |      0|none  |     0|acc     |0.3826|±  |0.0276|\n",
      "|  - prehistory                         |      0|none  |     0|acc     |0.4043|±  |0.0273|\n",
      "|  - professional_law                   |      0|none  |     0|acc     |0.3044|±  |0.0118|\n",
      "|  - world_religions                    |      0|none  |     0|acc     |0.4912|±  |0.0383|\n",
      "| - other                               |N/A    |none  |     0|acc     |0.4145|±  |0.0087|\n",
      "|  - business_ethics                    |      0|none  |     0|acc     |0.4500|±  |0.0500|\n",
      "|  - clinical_knowledge                 |      0|none  |     0|acc     |0.3623|±  |0.0296|\n",
      "|  - college_medicine                   |      0|none  |     0|acc     |0.3815|±  |0.0370|\n",
      "|  - global_facts                       |      0|none  |     0|acc     |0.2600|±  |0.0441|\n",
      "|  - human_aging                        |      0|none  |     0|acc     |0.3722|±  |0.0324|\n",
      "|  - management                         |      0|none  |     0|acc     |0.4466|±  |0.0492|\n",
      "|  - marketing                          |      0|none  |     0|acc     |0.5769|±  |0.0324|\n",
      "|  - medical_genetics                   |      0|none  |     0|acc     |0.3900|±  |0.0490|\n",
      "|  - miscellaneous                      |      0|none  |     0|acc     |0.4789|±  |0.0179|\n",
      "|  - nutrition                          |      0|none  |     0|acc     |0.3987|±  |0.0280|\n",
      "|  - professional_accounting            |      0|none  |     0|acc     |0.2908|±  |0.0271|\n",
      "|  - professional_medicine              |      0|none  |     0|acc     |0.3529|±  |0.0290|\n",
      "|  - virology                           |      0|none  |     0|acc     |0.4639|±  |0.0388|\n",
      "| - social_sciences                     |N/A    |none  |     0|acc     |0.3997|±  |0.0087|\n",
      "|  - econometrics                       |      0|none  |     0|acc     |0.2281|±  |0.0395|\n",
      "|  - high_school_geography              |      0|none  |     0|acc     |0.4141|±  |0.0351|\n",
      "|  - high_school_government_and_politics|      0|none  |     0|acc     |0.4301|±  |0.0357|\n",
      "|  - high_school_macroeconomics         |      0|none  |     0|acc     |0.3205|±  |0.0237|\n",
      "|  - high_school_microeconomics         |      0|none  |     0|acc     |0.3571|±  |0.0311|\n",
      "|  - high_school_psychology             |      0|none  |     0|acc     |0.4954|±  |0.0214|\n",
      "|  - human_sexuality                    |      0|none  |     0|acc     |0.4351|±  |0.0435|\n",
      "|  - professional_psychology            |      0|none  |     0|acc     |0.3693|±  |0.0195|\n",
      "|  - public_relations                   |      0|none  |     0|acc     |0.3455|±  |0.0455|\n",
      "|  - security_studies                   |      0|none  |     0|acc     |0.3184|±  |0.0298|\n",
      "|  - sociology                          |      0|none  |     0|acc     |0.5622|±  |0.0351|\n",
      "|  - us_foreign_policy                  |      0|none  |     0|acc     |0.4700|±  |0.0502|\n",
      "| - stem                                |N/A    |none  |     0|acc     |0.3108|±  |0.0082|\n",
      "|  - abstract_algebra                   |      0|none  |     0|acc     |0.2600|±  |0.0441|\n",
      "|  - anatomy                            |      0|none  |     0|acc     |0.3481|±  |0.0412|\n",
      "|  - astronomy                          |      0|none  |     0|acc     |0.3421|±  |0.0386|\n",
      "|  - college_biology                    |      0|none  |     0|acc     |0.3750|±  |0.0405|\n",
      "|  - college_chemistry                  |      0|none  |     0|acc     |0.3700|±  |0.0485|\n",
      "|  - college_computer_science           |      0|none  |     0|acc     |0.2900|±  |0.0456|\n",
      "|  - college_mathematics                |      0|none  |     0|acc     |0.2600|±  |0.0441|\n",
      "|  - college_physics                    |      0|none  |     0|acc     |0.3039|±  |0.0458|\n",
      "|  - computer_security                  |      0|none  |     0|acc     |0.4400|±  |0.0499|\n",
      "|  - conceptual_physics                 |      0|none  |     0|acc     |0.3021|±  |0.0300|\n",
      "|  - electrical_engineering             |      0|none  |     0|acc     |0.3103|±  |0.0386|\n",
      "|  - elementary_mathematics             |      0|none  |     0|acc     |0.2381|±  |0.0219|\n",
      "|  - high_school_biology                |      0|none  |     0|acc     |0.4419|±  |0.0283|\n",
      "|  - high_school_chemistry              |      0|none  |     0|acc     |0.2709|±  |0.0313|\n",
      "|  - high_school_computer_science       |      0|none  |     0|acc     |0.3600|±  |0.0482|\n",
      "|  - high_school_mathematics            |      0|none  |     0|acc     |0.2259|±  |0.0255|\n",
      "|  - high_school_physics                |      0|none  |     0|acc     |0.3377|±  |0.0386|\n",
      "|  - high_school_statistics             |      0|none  |     0|acc     |0.2546|±  |0.0297|\n",
      "|  - machine_learning                   |      0|none  |     0|acc     |0.2946|±  |0.0433|\n",
      "|winogrande                             |      1|none  |     0|acc     |0.6077|±  |0.0137|\n",
      "|boolq                                  |      2|none  |     0|acc     |0.6560|±  |0.0083|\n",
      "|hellaswag                              |      1|none  |     0|acc     |0.4894|±  |0.0050|\n",
      "|                                       |       |none  |     0|acc_norm|0.6547|±  |0.0047|\n",
      "|arc_challenge                          |      1|none  |     0|acc     |0.3481|±  |0.0139|\n",
      "|                                       |       |none  |     0|acc_norm|0.3720|±  |0.0141|\n",
      "|arc_easy                               |      1|none  |     0|acc     |0.6591|±  |0.0097|\n",
      "|                                       |       |none  |     0|acc_norm|0.6334|±  |0.0099|\n",
      "|piqa                                   |      1|none  |     0|acc     |0.7193|±  |0.0105|\n",
      "|                                       |       |none  |     0|acc_norm|0.7198|±  |0.0105|\n",
      "\n",
      "Average Acc: 54.90%\n"
     ]
    }
   ],
   "source": [
    "# Test Zero_shot\n",
    "import lm_eval\n",
    "from lm_eval.models.huggingface import HFLM\n",
    "from lm_eval.utils import make_table\n",
    "eval_tasks = 'piqa,arc_easy,arc_challenge,hellaswag,boolq,winogrande,mmlu'\n",
    "task_list = eval_tasks.split(',')\n",
    "model = HFLM(pretrained=model, batch_size=8)\n",
    "task_manager = lm_eval.tasks.TaskManager()\n",
    "results = lm_eval.simple_evaluate(\n",
    "        model=model,\n",
    "        tasks=task_list,\n",
    "        num_fewshot=0,\n",
    "        task_manager=task_manager,\n",
    "        )\n",
    "print(make_table(results))\n",
    "total_acc = 0\n",
    "for task in task_list:\n",
    "    total_acc += results['results'][task]['acc,none']\n",
    "print(f'Average Acc: {total_acc/len(task_list)*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frm-ptq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
